{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff36a688",
   "metadata": {},
   "source": [
    "# Qiskit Quantum Kernel Alignment (QKA) Test\n",
    "\n",
    "This notebook demonstrates Quantum Kernel Alignment using Qiskit Machine Learning.\n",
    "It performs regression on cardiac data using a Quantum Support Vector Regressor (QSVR) with an optimized quantum kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576604ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (2.2.3)\n",
      "Collecting qiskit-machine-learning\n",
      "  Downloading qiskit_machine_learning-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting qiskit-algorithms\n",
      "  Using cached qiskit_algorithms-0.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pandas in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: tqdm in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: seaborn in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: rustworkx>=0.15.0 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from qiskit) (0.17.1)\n",
      "Requirement already satisfied: numpy<3,>=1.17 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from qiskit) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.5 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from qiskit) (1.16.3)\n",
      "Requirement already satisfied: dill>=0.3 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from qiskit) (0.4.0)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from qiskit) (5.6.0)\n",
      "Requirement already satisfied: typing-extensions in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from qiskit) (4.15.0)\n",
      "Requirement already satisfied: setuptools>=40.1 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from qiskit-machine-learning) (80.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/leo07010/.conda/envs/cudaq-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading qiskit_machine_learning-0.9.0-py3-none-any.whl (263 kB)\n",
      "Using cached qiskit_algorithms-0.4.0-py3-none-any.whl (327 kB)\n",
      "Installing collected packages: qiskit-machine-learning, qiskit-algorithms\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [qiskit-algorithms]qiskit-algorithms]\n",
      "\u001b[1A\u001b[2KSuccessfully installed qiskit-algorithms-0.4.0 qiskit-machine-learning-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install qiskit qiskit-machine-learning qiskit-algorithms pandas scikit-learn tqdm seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8941d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from qiskit.circuit import QuantumCircuit, ParameterVector\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_machine_learning.algorithms import QSVR\n",
    "from qiskit_machine_learning.kernels.algorithms import QuantumKernelTrainer\n",
    "from qiskit_machine_learning.kernels import TrainableFidelityQuantumKernel\n",
    "from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
    "from qiskit_machine_learning.utils.loss_functions import KernelLoss\n",
    "from qiskit_machine_learning.optimizers import SPSA\n",
    "\n",
    "from qiskit.primitives import StatevectorSampler as Sampler\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "\n",
    "# Set random seed\n",
    "algorithm_globals.random_seed = 42\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c71b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Helper Functions\n",
    "# ==========================\n",
    "def get_upsampled_df(input_df: pd.DataFrame,\n",
    "                     total_n: int,\n",
    "                     add_label: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Upsample dataframe rows to reach a specified total number of rows.\n",
    "    \"\"\"\n",
    "    df = input_df.copy()\n",
    "    n_points = total_n - len(df) if total_n > len(df) else -1\n",
    "    if n_points > 0:\n",
    "        tmp_upsampled = df.sample(n=n_points, replace=True, random_state=0)\n",
    "\n",
    "        if add_label:\n",
    "            df[\"data_type\"] = \"original\"\n",
    "            tmp_upsampled[\"data_type\"] = \"bootstrap\"\n",
    "\n",
    "        df_upsampled = pd.concat([df, tmp_upsampled], axis=0)\n",
    "    else:\n",
    "        tmp_df = df.copy()\n",
    "        if add_label:\n",
    "            tmp_df[\"data_type\"] = \"original\"\n",
    "        df_upsampled = tmp_df\n",
    "\n",
    "    return df_upsampled\n",
    "\n",
    "\n",
    "def get_hold_out_test_split(modelling_df,\n",
    "                            split_col=\"sample\",\n",
    "                            mode=\"hold_out\",\n",
    "                            upsample_n=0):\n",
    "    \"\"\"\n",
    "    Perform hold-out split based on a column.\n",
    "    \"\"\"\n",
    "    training_datasets = {}\n",
    "    testing_datasets = {}\n",
    "    unique_split_col_values = modelling_df[split_col].unique()\n",
    "\n",
    "    for tmp_split in tqdm(unique_split_col_values, desc=\"Generating splits\"):\n",
    "        tmp_test_df = modelling_df[modelling_df[split_col] == tmp_split]\n",
    "        if mode == \"hold_out\":\n",
    "            tmp_train_df = modelling_df[modelling_df[split_col] != tmp_split]\n",
    "        else:\n",
    "            tmp_train_df = modelling_df[modelling_df[split_col] == tmp_split]\n",
    "\n",
    "        if upsample_n > 0:\n",
    "            tmp_train_df = get_upsampled_df(tmp_train_df, total_n=upsample_n)\n",
    "\n",
    "        training_datasets[f\"test_{tmp_split}\"] = tmp_train_df\n",
    "        testing_datasets[f\"test_{tmp_split}\"] = tmp_test_df\n",
    "\n",
    "    return training_datasets, testing_datasets\n",
    "\n",
    "\n",
    "def generate_combinations(genes, size=6):\n",
    "    combos = list(itertools.combinations(genes, size))\n",
    "    print(f\"Number of combinations of size {size}: {len(combos)}\")\n",
    "    return combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d665fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Custom Loss Function used for QKA\n",
    "# ==========================\n",
    "from qiskit_machine_learning.utils.loss_functions import KernelLoss\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "class SVRLoss(KernelLoss):\n",
    "    \"\"\"Kernel loss for regression using SVR.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.kwargs = kwargs\n",
    "        self.eval_count = 0\n",
    "\n",
    "    def evaluate(self, parameter_values, quantum_kernel, data, labels):\n",
    "        self.eval_count += 1\n",
    "        # 1) Update kernel parameters\n",
    "        quantum_kernel.assign_training_parameters(parameter_values)\n",
    "        # 2) Compute kernel matrix\n",
    "        K = quantum_kernel.evaluate(data)\n",
    "        # 3) Train SVR\n",
    "        svr = SVR(kernel=\"precomputed\", **self.kwargs)\n",
    "        svr.fit(K, labels)\n",
    "        # 4) Predict and compute MSE\n",
    "        y_pred = svr.predict(K)\n",
    "        loss_val = float(np.mean((labels - y_pred) ** 2))\n",
    "\n",
    "        if self.eval_count % 5 == 0:\n",
    "            print(f\"[SVR loss] call #{self.eval_count:3d}  MSE = {loss_val:.6f}\")\n",
    "\n",
    "        return loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957724ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating splits: 100%|██████████| 24/24 [00:00<00:00, 271.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Qiskit QKA: Using 4 qubits.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Data Loading & Config\n",
    "# ==========================\n",
    "y_col = \"Beat count per min\"\n",
    "meta_cols = [\"sample\"]\n",
    "# Load Data\n",
    "modelling_df = pd.read_csv(\"data/processed/cardiac_formatted_dataset-001.csv\", index_col=0)\n",
    "modelling_df = modelling_df.reset_index(drop=False)\n",
    "\n",
    "# Split Data\n",
    "training_datasets, testing_datasets = get_hold_out_test_split(\n",
    "    modelling_df, split_col=\"sample\"\n",
    ")\n",
    "\n",
    "# Features\n",
    "optimal_genes = [\n",
    "    \"H19\", \"MYL7\", \"NPPB\", \"MYL9\", \"TNNC1\", \"MYL4\",\n",
    "    \"TPM1\", \"UBC\", \"UBB\", \"TIMP1\", \"HSPB1\", \"HSPA8\", \"FTL\", \"FTH1\"\n",
    "]\n",
    "# trial_combinations = generate_combinations(optimal_genes, size=6)\n",
    "trial_gene_set = optimal_genes[:4] # Use first 4 for demo\n",
    "\n",
    "# Aggregate all training data for kernel training\n",
    "X_all = []\n",
    "y_all = []\n",
    "for hold_out_id in training_datasets.keys():\n",
    "    X_all.append(training_datasets[hold_out_id][trial_gene_set].values)\n",
    "    y_all.append(training_datasets[hold_out_id][y_col].values)\n",
    "\n",
    "X_all = np.vstack(X_all)\n",
    "y_all = np.concatenate(y_all)\n",
    "\n",
    "# Global Standardization & PCA\n",
    "global_scaler = StandardScaler()\n",
    "X_all_sc = global_scaler.fit_transform(X_all)\n",
    "\n",
    "global_pca = PCA(\n",
    "    n_components=min(8, X_all_sc.shape[0], X_all_sc.shape[1])\n",
    ")\n",
    "X_all_pca = global_pca.fit_transform(X_all_sc)\n",
    "\n",
    "n_qubits = X_all_pca.shape[1]\n",
    "print(f\"[Info] Qiskit QKA: Using {n_qubits} qubits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32cf1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3581963/185728895.py:5: DeprecationWarning: The class ``qiskit.circuit.library.data_preparation._zz_feature_map.ZZFeatureMap`` is deprecated as of Qiskit 2.1. It will be removed in Qiskit 3.0. Use the zz_feature_map function as a replacement. Note that this will no longer return a BlueprintCircuit, but just a plain QuantumCircuit.\n",
      "  feature_map = ZZFeatureMap(feature_dimension=n_qubits)\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Build Quantum Kernel\n",
    "# ==========================\n",
    "# Feature Map + Trainable Layer\n",
    "feature_map = ZZFeatureMap(feature_dimension=n_qubits)\n",
    "\n",
    "params_rx = ParameterVector(\"θx\", n_qubits)\n",
    "params_ry = ParameterVector(\"θy\", n_qubits)\n",
    "training_params = list(params_rx) + list(params_ry)\n",
    "\n",
    "qka_layer = QuantumCircuit(n_qubits)\n",
    "for i in range(n_qubits):\n",
    "    qka_layer.rx(params_rx[i], i)\n",
    "for i in range(n_qubits):\n",
    "    qka_layer.ry(params_ry[i], i)\n",
    "\n",
    "qka_circuit = feature_map.compose(qka_layer)\n",
    "\n",
    "# Trainable Kernel\n",
    "sampler = Sampler()\n",
    "fidelity = ComputeUncompute(sampler=sampler)\n",
    "\n",
    "quant_kernel = TrainableFidelityQuantumKernel(\n",
    "    fidelity=fidelity,\n",
    "    feature_map=qka_circuit,\n",
    "    training_parameters=training_params,\n",
    ")\n",
    "\n",
    "# Optimizer & Loss\n",
    "spsa_opt = SPSA(maxiter=10, learning_rate=0.1, perturbation=0.05)\n",
    "mse_loss = SVRLoss(C=1.0, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad0611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Quantum Kernel Training Start ===\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Train Kernel\n",
    "# ==========================\n",
    "print(\"=== Quantum Kernel Training Start ===\")\n",
    "qkt = QuantumKernelTrainer(\n",
    "    quantum_kernel=quant_kernel,\n",
    "    loss=mse_loss,\n",
    "    optimizer=spsa_opt,\n",
    "    initial_point=[np.pi / 2] * len(training_params),\n",
    ")\n",
    "\n",
    "qka_results = qkt.fit(X_all_pca, y_all)\n",
    "optimized_kernel = qka_results.quantum_kernel\n",
    "print(\"Optimal point:\", qka_results.optimal_point)\n",
    "print(\"=== Quantum Kernel Training Done ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e58c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Evaluation (LOOCV)\n",
    "# ==========================\n",
    "all_true, all_pred = [], []\n",
    "fold_results = []\n",
    "\n",
    "for hold_out_id in tqdm(training_datasets.keys(), desc=\"Running QKA-QSVR LOOCV\"):\n",
    "    # Prepare Data\n",
    "    Xtr = training_datasets[hold_out_id][trial_gene_set].values\n",
    "    ytr = training_datasets[hold_out_id][y_col].values\n",
    "    Xte = testing_datasets[hold_out_id][trial_gene_set].values\n",
    "    yte = testing_datasets[hold_out_id][y_col].values\n",
    "\n",
    "    # Standardize & PCA using Global Scaler/PCA\n",
    "    Xtr_sc = global_scaler.transform(Xtr)\n",
    "    Xte_sc = global_scaler.transform(Xte)\n",
    "\n",
    "    Xtr_pca = global_pca.transform(Xtr_sc)\n",
    "    Xte_pca = global_pca.transform(Xte_sc)\n",
    "\n",
    "    # QSVR with Optimized Kernel\n",
    "    qsvr = QSVR(quantum_kernel=optimized_kernel)\n",
    "    qsvr.fit(Xtr_pca, ytr)\n",
    "    y_pred = qsvr.predict(Xte_pca)\n",
    "\n",
    "    # Evaluate\n",
    "    rmse = float(np.sqrt(mean_squared_error(yte, y_pred)))\n",
    "    r2 = float(r2_score(yte, y_pred))\n",
    "    fold_results.append((hold_out_id, rmse, r2))\n",
    "\n",
    "    all_true.extend(list(yte))\n",
    "    all_pred.extend(list(y_pred))\n",
    "\n",
    "    print(f\"[{hold_out_id}] RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# ==========================\n",
    "# Summary\n",
    "# ==========================\n",
    "global_rmse = float(np.sqrt(mean_squared_error(all_true, all_pred)))\n",
    "global_r2 = float(r2_score(all_true, all_pred))\n",
    "\n",
    "print(\"\n",
    "========== QKA-QSVR LOOCV Results ==========\")\n",
    "for hid, rmse, r2 in fold_results:\n",
    "    print(f\"{hid:15s}  RMSE = {rmse:.4f},  R² = {r2:.4f}\")\n",
    "\n",
    "print(f\"\n",
    "[LOOCV Aggregate] RMSE = {global_rmse:.4f},  R² = {global_r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaq-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
